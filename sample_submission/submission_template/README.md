# Submission Template Prompts

This folder contains the prompt template files used by the `submit.py` script to dynamically generate prompts for the LLM during the ClinIQLink challenge. Each template corresponds to a specific QA pair type in the dataset.

## Files Included

- **list_template.prompt**: For list questions.
- **MC_template.prompt**: For multiple-choice questions.
- **multi_hop_template.prompt**: For multi-hop questions.
- **multi_hop_inverse_template.prompt**: For multi-hop inverse questions.
- **short_template.prompt**: For short answer questions.
- **short_inverse_template.prompt**: For short answer inverse questions.
- **tf_template.prompt**: For true/false questions.

## How It Works

1. **Extraction and Replacement**:  
   The `submit.py` script reads the QA dataset (in JSON format) and extracts the relevant fields (e.g., question text, options, correct/incorrect answers).  
   It then replaces the placeholders in these templates (e.g., `{question}`, `{options}`, etc.) with the actual values from the dataset.

2. **Prompt Generation**:  
   Once populated, the templates form the prompts that are sent to the LLM. These prompts instruct the LLM on how to answer each question type according to the specific format required.

3. **Evaluation Pipeline**:  
   The responses generated by the LLM are collected and then evaluated using custom metrics implemented in the `submit.py` script.

## Usage

- Ensure that the `submit.py` script is configured to read these prompt templates from this folder.
- The script dynamically builds the prompt by inserting the extracted QA data into the templates.
- The final prompt is sent to the model, and its output is processed and evaluated as part of the challenge workflow.

## Customization

You can NOT modify these templates. 
Any modifiaction to prompt template requests must be made to the CLinIQLink team.
